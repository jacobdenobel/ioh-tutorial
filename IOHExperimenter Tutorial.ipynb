{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fdf86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "    format='%(asctime)s %(levelname)s - %(message)s',\n",
    "    datefmt=\"%H:%M:%S\"\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "%rm -rf my-experiment*\n",
    "%rm -rf ioh_data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cf4c7e-1813-4414-9e38-e1efc3ad622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ioh\n",
    "%pip show ioh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f8621d",
   "metadata": {},
   "source": [
    "# Problem\n",
    "In ioh, everything revolves around the `problem` class, which exists for both `Real` and `Integer` types for continious and discrete problems resp. These classes are wrappers around an objective function, and can be used to interact with the various other parts of iohexperimenter. \n",
    "\n",
    "We have a number of objective functions already implemented for convenience, which includes the objective functions from the BBOB single objective benchmark by the COCO platform for the continous case and the PBO benchmark functions for the discrete case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbe3df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A list of problems can be accessed via the base classes\n",
    "ioh.problem.Real.problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9d10a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In order to instantiate a problem instance, we can do the following:\n",
    "problem = ioh.get_problem(\n",
    "    \"Sphere\", \n",
    "    instance=1,\n",
    "    dimension=10,\n",
    "    problem_type=\"Real\"\n",
    ")\n",
    "problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c8733f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The problem class includes information about the problem, which can be retrieved via the meta_data accessor\n",
    "problem.meta_data.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0264ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The current state of the problem, e.g. the number of evaluations, best seen points etc. are stored in the problems state.\n",
    "problem.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac1487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every problem as has a simple box-constraint associcated\n",
    "problem.constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f25a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can access the contraint information of the problem\n",
    "x0 = np.random.uniform(problem.constraint.lb, problem.constraint.ub)\n",
    "\n",
    "# Evaluation happens like a 'normal' objective function would\n",
    "problem(x0)\n",
    "\n",
    "# Whenever the problem is evaluated, the state changes\n",
    "problem.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f26c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to perform multiple runs with the same objective function, after every run, the problem has to be reset, \n",
    "# such that the internal state reflects the current run.\n",
    "def run_experiment(problem, algorithm, n_runs=5):\n",
    "    for run in range(n_runs):\n",
    "        \n",
    "        # Run the algorithm on the problem\n",
    "        algorithm(problem)\n",
    "\n",
    "        # print the best found for this run\n",
    "        print(f\"run: {run+1} - best found:{problem.state.current_best.y: .3f}\")\n",
    "\n",
    "        # Reset the problem\n",
    "        problem.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d775ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RandomSearch:\n",
    "    'Simple random search algorithm'\n",
    "    \n",
    "    n: int\n",
    "    length: float = 0.0\n",
    "        \n",
    "    def __call__(self, problem: ioh.problem.Real) -> None:\n",
    "        'Evaluate the problem n times with a randomly generated solution'\n",
    "        \n",
    "        for _ in range(self.n):\n",
    "            # We can use the problems constraint accessor to get information about the problem bounds\n",
    "            x = np.random.uniform(problem.constraint.lb, problem.constraint.ub)\n",
    "            self.length = np.linalg.norm(x)\n",
    "            \n",
    "            problem(x)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04699081-e241-493f-8f51-85f14c137df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the random search algorithm, we can then run a simple experiment\n",
    "run_experiment(problem, RandomSearch(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1d41c0",
   "metadata": {},
   "source": [
    "# Adding custom problems\n",
    "As the list of already implemented problems might not contains the objective function you would like to analyze and benchmark, we include an easy to use interface to wrap your benchmark function into an iohexperimenter `problem` object. \n",
    "\n",
    "Currently, only single objective functions are supported, so the only requirement on the function is its signature, which should take a single array parameter, and return a single floating point number $f(\\mathbf{x}) \\mapsto \\mathbb{R}$.\n",
    "\n",
    "In this example we will add the function (Styblinskiâ€“Tang):\n",
    "\n",
    "$f(\\mathbf{x}) = \\frac{\\sum_{i=1}^n x_i^4 - 16x_i^2 + 5x_i}{2}$\n",
    "\n",
    "defined on $[-5, 5]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f32b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def styblinski_tang(x: np.ndarray) -> float:\n",
    "    return np.sum(np.power(x, 4) - (16 * np.power(x, 2)) + (5 * x)) / 2\n",
    "\n",
    "\n",
    "styblinski_tang(np.array([-2.903534]*10)) # global minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb23a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can wrap this function in ioh, as this is is a continous function, we use wrap_real_problem:\n",
    "ioh.problem.wrap_real_problem(\n",
    "    styblinski_tang,                                     # Handle to the function\n",
    "    name=\"StyblinskiTang\",                               # Name to be used when instantiating\n",
    "    optimization_type=ioh.OptimizationType.Minimization, # Specify that we want to minimize\n",
    "    lb=-5,                                               # The lower bound\n",
    "    ub=5,                                                # The upper bound\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76f8aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create an instance of this problem, wrapped in ioh\n",
    "problem = ioh.get_problem(\"StyblinskiTang\", dimension=10)\n",
    "problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcedf9d9-29f9-4292-a7a7-d16a8bfdae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem(np.array([-2.903534]*10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ef70d4",
   "metadata": {},
   "source": [
    "## Specifying instances\n",
    "When doing bechmarking of custom problems, it can often be usefull to look at different instances of the same problem, but that perform some transformation the parameter or objective space, to test if an algorithm is invariant to such transformations. \n",
    "\n",
    "Here we add the following transformations to the aforementioned objective function:\n",
    "\n",
    "$T_x(\\mathbf{x}, c) = \\mathbf{x} + c$\n",
    "\n",
    "$T_y(y, c) = y * c$\n",
    "\n",
    "We can do this by providing transformation functions to the `wrap_problem` interface. Note that these take two parameters:\n",
    " 1. The operand they function on, which are the variables for the variables transformation and objective function value for the objective transformation. \n",
    " 2. An integer identifier of the instance id which is currently used. This allows you to specify alternate behavior for different instances.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200870f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables transformation R^d -> R^d\n",
    "def transform_variables(x: np.ndarray, instance_id:int) -> np.ndarray:\n",
    "    c = (instance_id - 1) * .5\n",
    "    return x + c\n",
    "\n",
    "# Objective transformation R -> R\n",
    "def transform_objectives(y: float, instance_id:int) -> float:\n",
    "    c = instance_id\n",
    "    return y * c\n",
    "\n",
    "# Note that we can overwrite a previously defined problem by calling wrap_real_problem again with the same name\n",
    "ioh.problem.wrap_real_problem(\n",
    "    styblinski_tang,                                     \n",
    "    name=\"StyblinskiTang\",                               \n",
    "    optimization_type=ioh.OptimizationType.Minimization, \n",
    "    lb=-5,                                               \n",
    "    ub=5,      \n",
    "    \n",
    "    # Adding the transformation functions\n",
    "    transform_variables=transform_variables,     \n",
    "    transform_objectives=transform_objectives\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b86e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now create different instances of the same problem\n",
    "instance1 = ioh.get_problem(\"StyblinskiTang\", instance=1, dimension=10)\n",
    "instance2 = ioh.get_problem(\"StyblinskiTang\", instance=2, dimension=10)\n",
    "instance1, instance2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20b5d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that when evaluating with the same point, each instance gives a different (transformed value)\n",
    "instance1(x0), instance2(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021fac60",
   "metadata": {},
   "source": [
    "# Logging data\n",
    "The default usage of IOHExperimenter is in generating logs of benchmarking experiments which can be analyzed in IOHAnalyzer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d4b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "logger = ioh.logger.Analyzer(\n",
    "    root=os.getcwd(),                  # Store data in the current working directory\n",
    "    folder_name=\"my-experiment\",       # in a folder named: 'my-experiment'\n",
    "    algorithm_name=\"random-search\",    # meta-data for the algorithm used to generate these results\n",
    "    store_positions=True               # store x-variables in the logged files\n",
    ")\n",
    "\n",
    "# this automatically creates a folder 'my-experiment' in the current working directory\n",
    "# if the folder already exists, it will given an additional number to make the name unique\n",
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e008c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to log data for a problem, we only have to attach it to a logger\n",
    "problem = ioh.get_problem(\"StyblinskiTang\", instance=1, dimension=2)\n",
    "problem.attach_logger(logger)\n",
    "\n",
    "# We can then run the random search as before, only now all data will be logged to a file\n",
    "run_experiment(problem, RandomSearch(10), n_runs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4207c311",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat my-experiment/IOHprofiler_f25_StyblinskiTang.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d820be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat my-experiment/data_f25_StyblinskiTang/IOHprofiler_f25_DIM2.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da18cd9",
   "metadata": {},
   "source": [
    "## Triggers \n",
    "The default behavior of the `Analyzer` logger is to log data only when there is an improvement of the objective value. We can change this behaviour, by specifying one or more triggers, which are logical operators, which when one of them evaluates to True, will cause data to be logged.\n",
    "\n",
    "We provide a number of trigger variants which can be use to customize the logging. In the following example, a trigger is defined which evaluates to True, every 3 function evaluations. It is combined with a trigger for improvement, so data will be logged on every 3rd function evaluation, or when there is an observed improvement of the objective value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3673e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "triggers = [\n",
    "    ioh.logger.trigger.Each(3),\n",
    "    ioh.logger.trigger.OnImprovement()\n",
    "]\n",
    "\n",
    "logger = ioh.logger.Analyzer(\n",
    "    root=os.getcwd(),                  \n",
    "    folder_name=\"my-experiment\",       \n",
    "    algorithm_name=\"random-search\",    \n",
    "    store_positions=True,\n",
    "    \n",
    "    # Add the triggers to the logger\n",
    "    triggers = triggers\n",
    ")\n",
    "\n",
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8720851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun the same experiment as before\n",
    "problem = ioh.get_problem(\"StyblinskiTang\", instance=1, dimension=2)\n",
    "problem.attach_logger(logger)\n",
    "run_experiment(problem, RandomSearch(10), n_runs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb16b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now see that data is logged either if there is improvement, or on every 3rd evaluation\n",
    "%cat my-experiment-1/data_f25_StyblinskiTang/IOHprofiler_f25_DIM2.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb4607",
   "metadata": {},
   "source": [
    "## Properties\n",
    "If we want to keep track of any dynamic parameters a given algorithm might have, we can use properties to log them to the output files. \n",
    "\n",
    "In the following example, we will track the length parameters for the RandomSearch algorithm, which is added for illustrative purpoposes, and changes for every function evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a125d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomSearch has a length parameter, which is dynamic\n",
    "algorithm = RandomSearch(10)\n",
    "\n",
    "# Creating a new logger\n",
    "logger = ioh.logger.Analyzer(\n",
    "    root=os.getcwd(),                  \n",
    "    folder_name=\"my-experiment\",       \n",
    "    algorithm_name=\"random-search\",    \n",
    "    store_positions=True\n",
    ")\n",
    "\n",
    "# Before we attach a problem, we tell the logger to keep track of the length parameter on algorithm\n",
    "logger.watch(algorithm, \"length\")\n",
    "\n",
    "# We can now again run the same experiment \n",
    "problem = ioh.get_problem(\"StyblinskiTang\", instance=1, dimension=2)\n",
    "\n",
    "problem.attach_logger(logger)\n",
    "run_experiment(problem, algorithm, n_runs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e13cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the additional length parameter being logged \n",
    "%cat my-experiment-2/data_f25_StyblinskiTang/IOHprofiler_f25_DIM2.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2642f5",
   "metadata": {},
   "source": [
    "# Alternate logging behaviour\n",
    "We provide a number of different loggers in addition to the `Analyzer` logger, which include:\n",
    " - `FlatFile` which logs data to a simple csv file\n",
    " - `Store` which keeps all of the stored data in memory\n",
    " - `EAF/EAH` which compute Empirical Attainment Function/Histogram statistics on the fly\n",
    "\n",
    "You can define your own custom logging behavoir by inheriting from the `AbstractLogger` class. The only required part of the interface is that you override the `__call__` operator, which takes a single `ioh.LogInfo` parameter. In this method you should define your desired behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad5d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple logger that logs data using the python logging module whenever it is triggeredd\n",
    "class MyLogger(ioh.logger.AbstractLogger):\n",
    "    def __call__(self, log_info: ioh.LogInfo):\n",
    "        logging.info(msg=f\"triggered! y: {log_info.current.y}\")\n",
    "\n",
    "\n",
    "# The abstract logger takes two parameters, triggers and properties\n",
    "mylogger = MyLogger(triggers=[ioh.logger.trigger.ALWAYS])\n",
    "\n",
    "problem = ioh.get_problem(\"StyblinskiTang\", instance=1, dimension=2)\n",
    "problem.attach_logger(mylogger)\n",
    "\n",
    "run_experiment(problem, RandomSearch(10), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b163d3e",
   "metadata": {},
   "source": [
    "# Standardized Experimental Setup (Python only)\n",
    "In Python, we provide the `Experiment` class which can be used to easily run a given algorithm over a larger number of problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f169dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = ioh.Experiment(\n",
    "    algorithm = RandomSearch(10), # An algorithm instance\n",
    "    fids = [1, 25],               # the id's of the problems we want to test\n",
    "    iids = [1, 10],               # the instances \n",
    "    dims = [2, 10],               # the dimensions\n",
    "    reps = 3,                     # the number of runs,\n",
    "    zip_output = True       \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d116207",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf7ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls ioh_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat ioh_data/IOHprofiler_f25_StyblinskiTang.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424db49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
